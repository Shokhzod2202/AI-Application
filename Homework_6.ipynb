{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwYTSa7J6nphzFu2zV0mYC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shokhzod2202/AI-Application/blob/main/Homework_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yip-c8i-zWu",
        "outputId": "237703e8-2764-4095-d641-53f4f8f42caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 41s 21ms/step - loss: 0.3275 - accuracy: 0.8979\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1502 - accuracy: 0.9573\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1271 - accuracy: 0.9644\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 38s 21ms/step - loss: 0.1041 - accuracy: 0.9707\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0971 - accuracy: 0.9732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c55ec3acbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Import TensorFlow and other required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels ), (test_images, test_labels ) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images/ 255.0\n",
        "\n",
        "# Initialize the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(128, activation ='relu',\n",
        "                                     return_sequences = True, input_shape =(28 , 28) ) ,\n",
        "    tf.keras.layers.SimpleRNN(128, activation ='relu') ,\n",
        "    tf.keras.layers.Dense(10, activation ='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile the model\n",
        "model.compile( optimizer = 'adam', loss ='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit( train_images , train_labels , epochs =5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activity 1: Implement a CNN with Dropout and Batch Normalization"
      ],
      "metadata": {
        "id": "ipOIwV9FIOXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Modify the existing model\n",
        "model = tf.keras.Sequential([\n",
        "    # Add a Convolutional layer with Batch Normalization and ReLU activation\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Add another Convolutional layer with Batch Normalization and ReLU activation\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the output\n",
        "    Flatten(),\n",
        "\n",
        "    # Add a Dense layer with Dropout and ReLU activation\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # You can adjust the dropout rate as needed\n",
        "\n",
        "    # Add the output Dense layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the modified model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n",
        "\n",
        "# Train the model with the modified architecture\n",
        "model.fit(train_images[..., np.newaxis], train_labels, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WComwOKdHzWQ",
        "outputId": "1801d928-3209-44e4-8cce-b45414c36d9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 26, 26, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 13, 13, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 11, 11, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 5, 5, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               204928    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225418 (880.54 KB)\n",
            "Trainable params: 225226 (879.79 KB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 82s 42ms/step - loss: 0.2150 - accuracy: 0.9365\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0991 - accuracy: 0.9725\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0752 - accuracy: 0.9787\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0639 - accuracy: 0.9813\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 76s 40ms/step - loss: 0.0520 - accuracy: 0.9852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c55b0416170>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All In One\n",
        "* Activity 2: Experiment with Different Activation Functions.\n",
        "* Activity 3: Add More Convolutional Layers.\n",
        "* Activity 4: Experiment with Different Optimizers.\n",
        "* Activity 5: Evaluate the Model with Test Data."
      ],
      "metadata": {
        "id": "R1Mn3gzIK2__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create and test models with different activation functions\n",
        "def create_and_test_model(activation_function):\n",
        "    # Load the MNIST dataset\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "    # Normalize the images\n",
        "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "    # Reshape the images to match the input shape expected by Conv2D layer\n",
        "    train_images = train_images[..., np.newaxis]\n",
        "    test_images = test_images[..., np.newaxis]\n",
        "\n",
        "    # Initialize the CNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with {activation_function} activation: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test the model with different activation functions\n",
        "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
        "for activation_function in activation_functions:\n",
        "    create_and_test_model(activation_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbGZ53-DBM5J",
        "outputId": "df0d7cf1-29a2-4ee9-8a3a-4f896afbcf8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.1515 - accuracy: 0.9561\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0703 - accuracy: 0.9805\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0579 - accuracy: 0.9837\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0448 - accuracy: 0.9878\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0376 - accuracy: 0.9894\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0280 - accuracy: 0.9932\n",
            "Test accuracy with relu activation: 99.32%\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 83s 43ms/step - loss: 0.1576 - accuracy: 0.9534\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 83s 45ms/step - loss: 0.0703 - accuracy: 0.9805\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0556 - accuracy: 0.9848\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 95s 50ms/step - loss: 0.0469 - accuracy: 0.9873\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 83s 45ms/step - loss: 0.0414 - accuracy: 0.9883\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0314 - accuracy: 0.9923\n",
            "Test accuracy with sigmoid activation: 99.23%\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.1536 - accuracy: 0.9558\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0704 - accuracy: 0.9798\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0560 - accuracy: 0.9841\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.0480 - accuracy: 0.9866\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0366 - accuracy: 0.9897\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0423 - accuracy: 0.9880\n",
            "Test accuracy with tanh activation: 98.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create, test and evaluate models with different optimizers and Test Data\n",
        "def create_test_and_evaluate_Model(optimizer_name):\n",
        "    # Load the MNIST dataset\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "    # Normalize the images\n",
        "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "    # Reshape the images to match the input shape expected by Conv2D layer\n",
        "    train_images = train_images[..., np.newaxis]\n",
        "    test_images = test_images[..., np.newaxis]\n",
        "\n",
        "    # Initialize the CNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model with the specified optimizer\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "    elif optimizer_name == 'Adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "    print(f\"Test accuracy with {optimizer_name}: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test the model with different optimizers\n",
        "optimizers_to_test = ['SGD', 'RMSprop', 'Adam']\n",
        "for optimizer_name in optimizers_to_test:\n",
        "    print(f\"Testing with optimizer: {optimizer_name}\")\n",
        "    create_test_and_evaluate_Model(optimizer_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBxIOZSTOnDx",
        "outputId": "5aa5311f-f649-414f-fae5-1d9f12fc614c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with optimizer: SGD\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.2557 - accuracy: 0.9227\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.1037 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0777 - accuracy: 0.9767\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 72s 39ms/step - loss: 0.0674 - accuracy: 0.9799\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0557 - accuracy: 0.9832\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0330 - accuracy: 0.9887\n",
            "Test accuracy with SGD: 98.87%\n",
            "Testing with optimizer: RMSprop\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.2300 - accuracy: 0.9383\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.1149 - accuracy: 0.9738\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 74s 40ms/step - loss: 0.0963 - accuracy: 0.9778\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0847 - accuracy: 0.9805\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0770 - accuracy: 0.9821\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0530 - accuracy: 0.9862\n",
            "Test accuracy with RMSprop: 98.62%\n",
            "Testing with optimizer: Adam\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 73s 38ms/step - loss: 0.2160 - accuracy: 0.9361\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0992 - accuracy: 0.9726\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0777 - accuracy: 0.9767\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 72s 39ms/step - loss: 0.0655 - accuracy: 0.9814\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0522 - accuracy: 0.9854\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0347 - accuracy: 0.9903\n",
            "Test accuracy with Adam: 99.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predictions on test data\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Example: Printing the predicted class for the first test image\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(f\"Predicted class for the first test image: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ea9aVlUO1fR",
        "outputId": "5e4c60f7-32a6-4822-e627-95aa6a797d48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0351 - accuracy: 0.9907\n",
            "Test accuracy: 99.07%\n",
            "Test loss: 0.0351\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Predicted class for the first test image: 7\n"
          ]
        }
      ]
    }
  ]
}