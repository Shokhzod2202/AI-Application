{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj+92nvUrR1ZeRTqvrLNCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shokhzod2202/AI-Application/blob/main/Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "PHneZiaI33H7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8GtHHCRI3eKB"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow and other required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We start by importing TensorFlow for building the RNN\n",
        "model and NumPy for numerical operations. For high school students, think\n",
        "of TensorFlow as your toolbox and NumPy as your set of mathematical\n",
        "instruments. You need both to build and understand neural networks.\n"
      ],
      "metadata": {
        "id": "Xp6CduSc3umB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "### 3.1 Loading and Preprocessing Data"
      ],
      "metadata": {
        "id": "8PCOuDf54OuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels ), (test_images, test_labels ) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images/ 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXn3lfcB3x8R",
        "outputId": "60272721-7b9e-4670-a06f-eaf98cb2bd86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We load the MNIST dataset and normalize the images by\n",
        "dividing each pixel value by 255. Normalizing makes it easier for the network\n",
        "to learn from the images. Think of this as simplifying a complex equation to\n",
        "make it easier to solve."
      ],
      "metadata": {
        "id": "jMm-f8Uv4cQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the RNN Model\n",
        "Model Architecture"
      ],
      "metadata": {
        "id": "QN3IPvf14jPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(128, activation ='relu',\n",
        "                                     return_sequences = True, input_shape =(28 , 28) ) ,\n",
        "    tf.keras.layers.SimpleRNN(128, activation ='relu') ,\n",
        "    tf.keras.layers.Dense(10, activation ='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "wGyFqIef4gEE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We build a simple RNN model with two RNN layers followed\n",
        "by a dense layer for classification. For high school students, you can think\n",
        "of the RNN layers as the ”brain” that learns from the data, and the dense\n",
        "layer as the ”decision-maker” that makes the final call."
      ],
      "metadata": {
        "id": "p5K38W5h7MO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling the Model\n",
        "Setting Optimizer and Loss Function"
      ],
      "metadata": {
        "id": "NtjHQ7Y07Xhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile( optimizer = 'adam', loss ='sparse_categorical_crossentropy', metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "Z8RJ0aU_7JZl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We compile the model using the Adam optimizer and sparse\n",
        "categorical cross-entropy as the loss function. Think of the optimizer as the\n",
        "method we use to improve our ”brain” (the model), and the loss function as\n",
        "the way we measure how well it’s doing."
      ],
      "metadata": {
        "id": "r9i2U61S75uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "### Fitting the Model"
      ],
      "metadata": {
        "id": "uLvuK8r88MeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit( train_images , train_labels , epochs =5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-H1NKRe71wo",
        "outputId": "3a369e89-a1ad-492e-869a-a7512675e681"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 41s 21ms/step - loss: 0.3486 - accuracy: 0.8891\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1517 - accuracy: 0.9574\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 40s 22ms/step - loss: 0.1258 - accuracy: 0.9656\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.1060 - accuracy: 0.9710\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0963 - accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a6653f694b0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We train the model using the training data for 5 epochs. An\n",
        "epoch is one complete look at the entire dataset. Think of this as the ”study\n",
        "time” for our model to learn from the data."
      ],
      "metadata": {
        "id": "TkmklTDH8YjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "-3QnqWlt8ej2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate (test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLGPBvs-8IiC",
        "outputId": "3a4ac9f8-7de1-41cc-9c2f-a2ec4d332648"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0930 - accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: Finally, we evaluate the model using the test dataset to check\n",
        "its performance. This is like a ”final exam” for our model to see how well it\n",
        "has learned from the training data."
      ],
      "metadata": {
        "id": "og9NbzlC8UyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and Loading the Model for Testing\n",
        "### Saving the Model"
      ],
      "metadata": {
        "id": "REQcaVCZ88K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('my_rnn_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBkkd78v84PU",
        "outputId": "acea79dc-1f86-4226-b49f-b7f4bb7ccdbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We save the trained model to a file so that we can use it later\n",
        "without having to retrain it. Think of this as saving your game progress in\n",
        "a video game; you can pick up right where you left off."
      ],
      "metadata": {
        "id": "tbCJeDF89rMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Model"
      ],
      "metadata": {
        "id": "NbEBYaqe9whD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model('my_rnn_model.h5')"
      ],
      "metadata": {
        "id": "rgqMwNM49kh5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We load the saved model from the file. This allows us to\n",
        "continue using the model for making predictions or even continue training it.\n",
        "It’s like loading your saved game progress to continue playing."
      ],
      "metadata": {
        "id": "M8Xtzv-Q-EE5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yK_VTSTG9__e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}